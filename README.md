# Git Practice
## Bias in AI-based models for medical applications: challenges and mitigation strategies
A link to the article can be found [here](https://www.nature.com/articles/s41746-023-00858-z).

## Article thoughts
This article discusses biases in AI models used for medical purposes and explores possible solutions. Something I found interesting is that bias in medical models is prevalent due to the biases that exist in the training data. The article cites "data collection/preparation, model development, model evaluation, and deployment in clinical settings" as potential sources of bias. This raises a few questionsâ€”how can we obtain data suitable to train models? Should we use datasets that were obtained from a broader group, or take from data that was taken from a narrower population? Additionally, can we create software that can detect bias in training data? These are all concerns that are still being addressed, but remain critical as AI takes its place in the medical field in the coming years. 



